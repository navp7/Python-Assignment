{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1652852a-e87b-4e44-a051-5bd53e2a9662",
   "metadata": {},
   "source": [
    "# Naïve bayes-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce7ed-0e28-42dd-b3ee-aefbf68d5e42",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba6ab8d-9076-4975-a383-67ca6212300d",
   "metadata": {},
   "source": [
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, you can use conditional probability. You are looking for \\(P(\\text{Smoker} | \\text{Uses Health Insurance})\\).\n",
    "\n",
    "You are given the following information:\n",
    "- \\(P(\\text{Uses Health Insurance}) = 0.70\\)\n",
    "- \\(P(\\text{Smoker} | \\text{Uses Health Insurance}) = 0.40\\)\n",
    "\n",
    "You can use the formula for conditional probability:\n",
    "\n",
    "\\[P(A | B) = \\frac{P(A \\text{ and } B)}{P(B)}\\]\n",
    "\n",
    "In this case:\n",
    "- \\(A\\) is the event \"Smoker.\"\n",
    "- \\(B\\) is the event \"Uses Health Insurance.\"\n",
    "\n",
    "So, you want to find \\(P(\\text{Smoker} | \\text{Uses Health Insurance})\\), which can be calculated as:\n",
    "\n",
    "\\[P(\\text{Smoker} | \\text{Uses Health Insurance}) = \\frac{P(\\text{Smoker and Uses Health Insurance})}{P(\\text{Uses Health Insurance})}\\]\n",
    "\n",
    "Substitute the given values:\n",
    "\n",
    "\\[P(\\text{Smoker | Uses Health Insurance}) = \\frac{0.40 \\cdot 0.70}{0.70}\\]\n",
    "\n",
    "Now, calculate the probability:\n",
    "\n",
    "\\[P(\\text{Smoker | Uses Health Insurance}) = \\frac{0.28}{0.70} = 0.4\\]\n",
    "\n",
    "So, the probability that an employee is a smoker, given that he/she uses the health insurance plan, is 0.40 or 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7148b4-85c8-4a9f-ad31-7d02a68f8804",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cc5de-2a38-45fb-924e-f939324d883f",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two different variants of the Naive Bayes classifier, and they are commonly used for different types of data:\n",
    "\n",
    "**Bernoulli Naive Bayes:**\n",
    "- Suitable for binary and categorical data.\n",
    "- Assumes that features are binary (0/1) variables, typically representing the absence or presence of a feature in a document or sample.\n",
    "- Often used in text classification problems, such as spam detection, where features represent the occurrence of words in a document.\n",
    "\n",
    "**Multinomial Naive Bayes:**\n",
    "- Primarily used for text classification tasks.\n",
    "- Assumes that features represent the counts or frequencies of words or terms in a document.\n",
    "- Works well with data where features are discrete and represent counts of occurrences, such as the frequency of words in a document.\n",
    "\n",
    "In summary, the key difference lies in the nature of the features and the type of data they are designed to handle. Bernoulli Naive Bayes is suitable for binary and categorical features, while Multinomial Naive Bayes is designed for count-based, discrete features, especially in text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e8f28-0051-4ecb-a6af-16f1636d96c5",
   "metadata": {},
   "source": [
    "### Q3. How does Bernoulli Naive Bayes handle missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc4da2-96a2-45ed-9982-bad14d4d299f",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes typically assumes binary features (0/1), and missing values can be treated as a specific category, similar to how it handles other values. If a feature is missing for a particular sample, it is treated as if it's not present (0) for that sample. This approach is appropriate when dealing with binary data, where the absence or presence of a feature is the focus. Missing values are essentially treated as the absence of the feature in the document or sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb115e-bc56-4b63-b10d-fac615f07791",
   "metadata": {},
   "source": [
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad75110-67f0-4abf-859e-bf8faee5d404",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. While it is often associated with binary or continuous data, it can also be extended to handle multi-class problems. In the case of multi-class classification, you would typically have more than two classes, and each class would have its own set of Gaussian (normal) distribution parameters for each feature.\n",
    "\n",
    "Gaussian Naive Bayes assumes that the features within each class follow a Gaussian distribution (normal distribution). To apply it to multi-class problems, you would calculate the class-specific mean and variance for each feature for each class. Then, when making predictions for a new instance, you calculate the probability of the instance belonging to each class based on the Gaussian distribution parameters and choose the class with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3fa38-b4f8-444d-ab16-ff783582ab77",
   "metadata": {},
   "source": [
    "### Q5. Assignment:\n",
    "    \n",
    "Data preparation:\n",
    "    \n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26aca37d-7326-4eb8-a988-7d61446a3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40682233-35df-4025-8cac-2a70e0a75fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428e46b2-db2d-4004-9781-4d7f654d74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae05aac-6dcf-4d60-8bfb-ee56cb6bb0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0                0.00            0.00  ...                   0.0        0.000   \n",
       "1                0.00            0.94  ...                   0.0        0.000   \n",
       "2                0.64            0.25  ...                   0.0        0.010   \n",
       "3                0.31            0.63  ...                   0.0        0.000   \n",
       "4                0.31            0.63  ...                   0.0        0.000   \n",
       "...               ...             ...  ...                   ...          ...   \n",
       "4596             0.00            0.00  ...                   0.0        0.000   \n",
       "4597             0.00            0.00  ...                   0.0        0.000   \n",
       "4598             0.00            0.00  ...                   0.0        0.102   \n",
       "4599             0.00            0.00  ...                   0.0        0.000   \n",
       "4600             0.00            0.00  ...                   0.0        0.000   \n",
       "\n",
       "      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0           0.000          0.0        0.778        0.000        0.000   \n",
       "1           0.132          0.0        0.372        0.180        0.048   \n",
       "2           0.143          0.0        0.276        0.184        0.010   \n",
       "3           0.137          0.0        0.137        0.000        0.000   \n",
       "4           0.135          0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4596        0.232          0.0        0.000        0.000        0.000   \n",
       "4597        0.000          0.0        0.353        0.000        0.000   \n",
       "4598        0.718          0.0        0.000        0.000        0.000   \n",
       "4599        0.057          0.0        0.000        0.000        0.000   \n",
       "4600        0.000          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  \n",
       "0                          278  \n",
       "1                         1028  \n",
       "2                         2259  \n",
       "3                          191  \n",
       "4                          191  \n",
       "...                        ...  \n",
       "4596                        88  \n",
       "4597                        14  \n",
       "4598                       118  \n",
       "4599                        78  \n",
       "4600                        40  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd415f05-1101-4aa9-83f4-3ea05c0a171a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "...     ...\n",
       "4596      0\n",
       "4597      0\n",
       "4598      0\n",
       "4599      0\n",
       "4600      0\n",
       "\n",
       "[4601 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63594972-4d95-4478-802d-10f97b0023d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "869f6c9c-5ed4-4a57-969f-3fe82ec045c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9efa6eb6-2ba6-45e8-8959-44353b7d81f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  Label  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f632286-4160-49df-95a7-cdf966bf6c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000   \n",
       "max       4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total        Label  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50173373-fbf2-4d0b-8335-24dd7519f83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_;                 4601 non-null   float64\n",
      " 49  char_freq_(                 4601 non-null   float64\n",
      " 50  char_freq_[                 4601 non-null   float64\n",
      " 51  char_freq_!                 4601 non-null   float64\n",
      " 52  char_freq_$                 4601 non-null   float64\n",
      " 53  char_freq_#                 4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  Label                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02bbcbd-2524-42a2-aa93-858a8402b1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_#                   0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "Label                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20501d7-a348-4a82-99e3-906f5bf84c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for counting ham and spam\n",
    "\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc5a18-30c8-4fa7-b47b-ffddd7b99c4d",
   "metadata": {},
   "source": [
    "#### There are 2788 - ham and 1813 spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd2b517-1328-4e41-a55c-5cc46afdf604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Spam(1)  and Ham(0)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting graph for distribution\n",
    "\n",
    "sns.countplot(x = \"Label\", data = df)\n",
    "plt.title('Distribution of Spam(1)  and Ham(0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "501e4a74-6f23-484b-a8b0-49e73bb8d225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4601, 58), (4601, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Train and Test\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b7c33a-d0dd-498c-8a87-add7277ffabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50c9bfb-40d1-450c-800b-216f364e596b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3680, 58), (3680, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f50b8f-015f-49da-8936-5df8dd2592ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921, 58), (921, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8f0d3-c614-4c66-b53d-81986fcbbd4e",
   "metadata": {},
   "source": [
    "### Since the dataset contains features with continous value its advisable to follow Multinomial Naive Baye's Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cab02046-179f-47a1-82f3-4d562650dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d2382bf-ef0a-44c1-bde5-a296fd00563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bern_NB = BernoulliNB()\n",
    "gaus_NB = GaussianNB()\n",
    "multi_NB =MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff7c09-5fd9-46d6-afac-06bc459e8051",
   "metadata": {},
   "source": [
    "## Model with Bernoulli Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6460ec76-1b79-4c24-8b12-bd11e87b4be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c246e98-2504-45fa-958d-05845797cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_B=bern_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "194e6049-259a-4c92-ac4e-0d3b8f55edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       544\n",
      "           1       0.99      0.97      0.98       377\n",
      "\n",
      "    accuracy                           0.98       921\n",
      "   macro avg       0.98      0.98      0.98       921\n",
      "weighted avg       0.98      0.98      0.98       921\n",
      "\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[539   5]\n",
      " [ 12 365]]\n",
      "------------------------------------------------\n",
      "Test Accuracy for Bernaulli Naive Bayes is 0.9815418023887079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_B))\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_B))\n",
    "print('------------------------------------------------')\n",
    "print('Test Accuracy for Bernaulli Naive Bayes is',accuracy_score(y_test,y_pred_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7e9a1-bb86-4f92-bd84-951b5cc2d9e5",
   "metadata": {},
   "source": [
    "## Model with Multinomial Naive Bayes's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcb841f3-f5e4-428d-a27a-4f06acda4473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "540dd15a-f29d-4518-9040-38bdce9c4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_M=multi_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a12fc1c-b152-46ab-95ef-c311d2bb59a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       544\n",
      "           1       0.79      0.84      0.82       377\n",
      "\n",
      "    accuracy                           0.84       921\n",
      "   macro avg       0.84      0.84      0.84       921\n",
      "weighted avg       0.85      0.84      0.85       921\n",
      "\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[462  82]\n",
      " [ 61 316]]\n",
      "------------------------------------------------\n",
      "Test Accuracy for Multinomial Naive Bayes is 0.8447339847991314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_M))\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_M))\n",
    "print('------------------------------------------------')\n",
    "print('Test Accuracy for Multinomial Naive Bayes is',accuracy_score(y_test,y_pred_M))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fce635-695e-46a9-bb18-b52dfa1713bb",
   "metadata": {},
   "source": [
    "## Model with Gaussian Naive Bayes's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f40ff62-825e-4300-ade3-b965399b445e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaus_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87adce9f-d847-40d9-b327-360e9bd64276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_G=multi_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c273eeda-c372-47e0-9516-d06cc311da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       544\n",
      "           1       0.79      0.84      0.82       377\n",
      "\n",
      "    accuracy                           0.84       921\n",
      "   macro avg       0.84      0.84      0.84       921\n",
      "weighted avg       0.85      0.84      0.85       921\n",
      "\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[462  82]\n",
      " [ 61 316]]\n",
      "------------------------------------------------\n",
      "Test Accuracy for Gaussian Naive Bayes is 0.8447339847991314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_G))\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_G))\n",
    "print('------------------------------------------------')\n",
    "print('Test Accuracy for Gaussian Naive Bayes is',accuracy_score(y_test,y_pred_G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c517be4-311b-4fa5-9ea0-ed6233e08fcd",
   "metadata": {},
   "source": [
    "### Lets check the accuracy for each model with K_Fold Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a43fe43-9ee7-4012-bd84-aa5688b6cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append (('Bernoulli_NB',bern_NB))\n",
    "models.append (('Multinomia_NB',multi_NB))\n",
    "models.append (('Gaussian_NB',gaus_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbdec5cc-dbba-4e8f-8293-f03863791d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli_NB: 0.979348\n",
      "Multinomia_NB: 0.842663\n",
      "Gaussian_NB: 0.998641\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names =[]\n",
    "\n",
    "for name, model in models:\n",
    "    kfold=KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model,X_train,y_train,cv = kfold, scoring = 'accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f\"%(name,cv_results.mean())\n",
    "    print(msg)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f04aea-097a-4241-9182-763e95f22fcb",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "#### For Bernoulli NB: \n",
    "-- Without CV accuracy is 0.9815418023887079\n",
    "-- With CV accuracy is 0.979348\n",
    "__\n",
    "#### For Multinomial NB: \n",
    "-- Without CV accuracy is 0.8447339847991314\n",
    "-- With CV accuracy is 0.842663\n",
    "__\n",
    "#### For Gaussian NB: \n",
    "-- Without CV accuracy is 0.8447339847991314\n",
    "-- With CV accuracy is 0.998641\n",
    "\n",
    "#### In this case, With CV Gaussian Naive Baye's perform very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25978185-4dec-4562-93c3-091117578b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
