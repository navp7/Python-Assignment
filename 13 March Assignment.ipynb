{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efdda3d-53c1-4fe1-882b-5ad84ab20050",
   "metadata": {},
   "source": [
    "### 13 March Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bcb81c-bf25-4f4a-8015-e38110b8331f",
   "metadata": {},
   "source": [
    "### Statistics Advance-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97800f00-85d4-4a48-8220-22158672af27",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f748af-a60f-4702-89e1-330b55d84543",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across two or more groups to determine if there are significant differences among them. ANOVA makes several assumptions about the data in order to provide valid results. Violations of these assumptions can impact the reliability and validity of ANOVA results. The key assumptions of ANOVA are:\n",
    "\n",
    "1. **Independence**: The observations within each group are independent of each other. This means that the values in one group do not influence the values in another group.\n",
    "\n",
    "2. **Normality**: The distribution of the dependent variable (outcome) within each group is approximately normal. Deviations from normality can affect the Type I error rate (false positive rate) of the test.\n",
    "\n",
    "3. **Homogeneity of Variance**: The variance of the dependent variable is approximately equal across all groups. Unequal variances can lead to inflated Type I error rates and impact the validity of ANOVA results.\n",
    "\n",
    "Examples of Violations and Impact on Validity:\n",
    "\n",
    "1. **Non-Independence**: If observations within groups are not independent, it can lead to pseudoreplication and inflated Type I error rates. For instance, repeated measurements on the same subjects or subjects who are related (e.g., family members) violate the independence assumption.\n",
    "\n",
    "2. **Non-Normality**: If the distribution of the dependent variable is significantly non-normal in one or more groups, it can impact the reliability of ANOVA results. This can lead to increased Type I or Type II errors. For example, if the data is highly skewed or has heavy tails, the assumption of normality may be violated.\n",
    "\n",
    "3. **Homogeneity of Variance**: Violations of homogeneity of variance can lead to incorrect conclusions about group differences. If one group has a significantly larger variance than others, it can influence the F-statistic, leading to inflated Type I error rates. This is known as the \"heteroscedasticity\" violation.\n",
    "\n",
    "Addressing Violations:\n",
    "\n",
    "- If the assumptions are mildly violated, ANOVA may still be robust enough to provide valid results.\n",
    "- For normality violations, transformations (e.g., log transformation) might be applied to make the data more normally distributed.\n",
    "- For heteroscedasticity, a Welch's ANOVA or other robust methods can be used if group sizes are unequal or variances are not equal.\n",
    "- Non-independence can often be addressed through appropriate study design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07627bd0-41ea-4d7b-9db1-3b7bf5074776",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddef10e-5c6f-41b1-992b-cf161a2a4b39",
   "metadata": {},
   "source": [
    "There are three main types of Analysis of Variance (ANOVA) techniques: One-Way ANOVA, Two-Way ANOVA, and Multivariate ANOVA (MANOVA). Each type of ANOVA is used in different situations to analyze the variability among groups or factors. Here's a brief overview of each type and when it would be used:\n",
    "\n",
    "1. **One-Way ANOVA**:\n",
    "   - Situation: Used when you have one categorical independent variable (factor) with more than two levels (groups), and you want to compare means across these groups.\n",
    "   - Example: Comparing the performance of students in three different teaching methods (A, B, C) to determine if there are significant differences in their test scores.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - Situation: Used when you have two categorical independent variables (factors) and you want to examine their individual effects as well as their interaction effect on a continuous dependent variable.\n",
    "   - Example: Analyzing the effects of both gender (male, female) and diet type (high protein, low protein) on weight loss.\n",
    "\n",
    "3. **Multivariate ANOVA (MANOVA)**:\n",
    "   - Situation: Used when you have multiple continuous dependent variables and multiple categorical independent variables (factors), and you want to test for overall differences among groups.\n",
    "   - Example: Investigating the impact of different levels of exercise intensity (low, moderate, high) and dietary habits (vegetarian, non-vegetarian) on multiple health outcomes (weight, blood pressure, cholesterol level).\n",
    "\n",
    "Each type of ANOVA helps address specific research questions and hypotheses related to group differences and interactions. It's important to choose the appropriate type of ANOVA based on your study design and the nature of your data. Additionally, checking the assumptions of ANOVA and considering alternatives (such as non-parametric tests) is essential to ensure the validity of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01b823-bd48-4a3e-ac02-b27e8a89330a",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3eef2-0488-4a19-a77c-5f4dce23b1cb",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the total sum of squares (SST) measures the total variability in the data, the explained sum of squares (SSE) measures the variability explained by the group means, and the residual sum of squares (SSR) measures the unexplained variability or error. You can calculate these sums of squares using Python. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([15, 18, 20, 22, 25])\n",
    "group2 = np.array([30, 32, 35, 38, 40])\n",
    "group3 = np.array([50, 52, 55, 58, 60])\n",
    "\n",
    "# Combine the data from all groups\n",
    "all_data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((all_data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((group1_mean - overall_mean) ** 2) * len(group1) + \\\n",
    "      np.sum((group2_mean - overall_mean) ** 2) * len(group2) + \\\n",
    "      np.sum((group3_mean - overall_mean) ** 2) * len(group3)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Print results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "```\n",
    "\n",
    "In this example, `group1`, `group2`, and `group3` represent the data for each group. The `all_data` array contains the combined data from all groups. The overall mean and group means are calculated. The sums of squares are computed using the formulas:\n",
    "\n",
    "- SST = \\(\\sum_{i=1}^{N} (x_i - \\bar{x})^2\\)\n",
    "- SSE = \\(\\sum_{i=1}^{k} n_i (\\bar{x}_i - \\bar{x})^2\\)\n",
    "- SSR = SST - SSE\n",
    "\n",
    "Where \\(N\\) is the total number of observations, \\(k\\) is the number of groups, \\(n_i\\) is the number of observations in group \\(i\\), \\(x_i\\) is an individual observation, and \\(\\bar{x}_i\\) is the mean of group \\(i\\).\n",
    "\n",
    "These calculations help you understand the distribution of variance in the data and the extent to which group means explain the overall variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848e3ac-3923-4404-8697-aaadfb315641",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0821d2-4390-4f74-bf45-05ad64086a79",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by analyzing the variance attributed to each factor and their interactions. Here's how you can calculate main effects and interaction effects using Python and the `statsmodels` library:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with sample data\n",
    "data = {\n",
    "    'A': [10, 15, 20, 25, 30, 12, 18, 24, 28, 32],\n",
    "    'B': [8, 12, 16, 20, 24, 11, 14, 17, 20, 23],\n",
    "    'Y': [22, 27, 32, 37, 42, 25, 30, 35, 40, 45]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('Y ~ A + B + A:B', data=df).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "```\n",
    "\n",
    "In this example, we have created a DataFrame `df` with three columns: 'A', 'B', and 'Y'. 'A' and 'B' represent the levels of the two factors, and 'Y' represents the dependent variable.\n",
    "\n",
    "The `ols` function is used to fit the two-way ANOVA model with the formula 'Y ~ A + B + A:B', which includes the main effects of factors 'A' and 'B' as well as their interaction ('A:B'). The `anova_lm` function from `statsmodels.stats` is used to print the ANOVA table, which includes information about main effects, interaction effects, and more.\n",
    "\n",
    "In the ANOVA table, you'll find the sum of squares (SS), degrees of freedom (DF), mean squares (MS), F-statistic, and p-value for each factor (main effects 'A' and 'B') and their interaction ('A:B'). The p-values help you determine if these effects are statistically significant.\n",
    "\n",
    "Interpretation:\n",
    "- If the p-value is less than your chosen significance level (e.g., 0.05), you would conclude that the corresponding effect (main effect or interaction) is statistically significant.\n",
    "- If the p-value is greater than the significance level, you would conclude that there is no significant evidence for that effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c34d5d-3f9f-4316-9a0f-e6c5a5a339c6",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b32b9-3672-443d-a346-424d08e269a1",
   "metadata": {},
   "source": [
    "Given an F-statistic of 5.23 and a p-value of 0.02:\n",
    "\n",
    "1. **Null Hypothesis (H0)**: The null hypothesis states that there are no significant differences between the group means. In other words, all group means are equal.\n",
    "\n",
    "2. **Alternative Hypothesis (Ha)**: The alternative hypothesis states that there are significant differences between at least two group means.\n",
    "\n",
    "Based on the p-value:\n",
    "\n",
    "- Since the p-value (0.02) is less than the chosen significance level (e.g., 0.05), you would reject the null hypothesis.\n",
    "\n",
    "Interpretation of Conclusions:\n",
    "\n",
    "- You have found statistically significant evidence to conclude that there are significant differences between at least some of the group means.\n",
    "- However, the p-value does not provide information about which specific groups are different from each other; it only tells you that differences exist somewhere among the groups.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you would conclude that there are significant differences between at least some of the group means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734c5fd-fcd0-4582-a544-94c6c88b1348",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c17ab-b58e-40e7-b9d5-be97d13e8931",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is essential to ensure the validity of your analysis. There are various methods to handle missing data, each with its own potential consequences. Here's how you can handle missing data and the potential consequences of using different methods:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion)**:\n",
    "   - This method involves analyzing only the cases with complete data for all variables.\n",
    "   - Consequences:\n",
    "     - Loss of valuable information: You discard all cases with missing data, which may reduce the representativeness of your sample and reduce statistical power.\n",
    "     - Biased results: If the missing data are not missing completely at random (MCAR), this method can lead to biased estimates.\n",
    "\n",
    "2. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean value of the variable.\n",
    "   - Consequences:\n",
    "     - Distortion of variances: This method artificially reduces the variability of the variable, which can lead to underestimated standard errors and inflated F-statistics.\n",
    "     - Attenuation of correlations: Mean imputation can artificially reduce the correlations between variables.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Missing values are replaced with the last observed value for that subject.\n",
    "   - Consequences:\n",
    "     - Temporal bias: LOCF assumes that the missing value remains the same as the last observed value, which may not be accurate.\n",
    "     - Overestimation of treatment effects: If missing data occur more frequently in the control group, for example, LOCF can lead to an overestimation of treatment effects.\n",
    "\n",
    "4. **Multiple Imputation**:\n",
    "   - Missing values are imputed multiple times, creating several datasets with imputed values. The analyses are performed on each dataset, and the results are combined.\n",
    "   - Consequences:\n",
    "     - Time-consuming: Multiple imputation involves multiple iterations and can be computationally intensive.\n",
    "     - Assumes missing at random (MAR): The validity of results depends on the accuracy of the imputation model and the assumption that missing data are MAR.\n",
    "\n",
    "5. **Maximum Likelihood Estimation (MLE)**:\n",
    "   - This method estimates model parameters that maximize the likelihood of observed data.\n",
    "   - Consequences:\n",
    "     - Complex implementation: MLE involves solving complex likelihood equations and may require specialized software.\n",
    "     - Requires model assumptions: MLE assumes a specific model for the data distribution.\n",
    "\n",
    "When handling missing data in a repeated measures ANOVA, it's important to consider the nature of your data, the extent of missingness, and the assumptions of the missing data mechanism. In practice, a combination of methods (e.g., multiple imputation, sensitivity analysis) might be used to address missing data and assess the robustness of results. Careful consideration and reporting of the chosen method and potential implications are essential for ensuring the validity and reliability of your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1855a-4391-4892-92d0-067344fbaff0",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5694f-265b-4d93-9960-e8dbf2c57eb2",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to determine which specific groups have significant differences in means when the ANOVA indicates an overall significant difference. These tests help identify pairwise comparisons that contribute to the significant result. Some common post-hoc tests include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - When to use: Tukey's HSD is used when you have conducted a one-way ANOVA and want to perform all possible pairwise comparisons.\n",
    "   - Example: You conducted an ANOVA to compare the effectiveness of three different treatments on pain relief. Tukey's HSD would help you identify which specific treatment pairs have significantly different effects.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - When to use: Bonferroni correction is used to control the family-wise error rate when conducting multiple pairwise comparisons.\n",
    "   - Example: You conducted an ANOVA to compare the performance of five different advertising strategies. Since you are making multiple comparisons, Bonferroni correction can help reduce the chance of making a Type I error.\n",
    "\n",
    "3. **Duncan's Multiple Range Test (MRT)**:\n",
    "   - When to use: Duncan's MRT is used to identify significantly different groups among multiple pairwise comparisons.\n",
    "   - Example: You conducted an ANOVA to compare the yields of six different fertilizer treatments. Duncan's MRT would help you determine which fertilizer treatments result in significantly different yields.\n",
    "\n",
    "4. **Scheffé Test**:\n",
    "   - When to use: Scheffé test is used when you want to control the family-wise error rate with more leniency compared to Bonferroni correction.\n",
    "   - Example: You conducted an ANOVA to compare the reaction times under three different conditions. Scheffé test would help identify which condition pairs have significantly different effects.\n",
    "\n",
    "5. **Holm-Bonferroni Method**:\n",
    "   - When to use: Holm-Bonferroni method is a modified version of the Bonferroni correction that provides greater statistical power.\n",
    "   - Example: You conducted an ANOVA to compare the effectiveness of four different diets on weight loss. The Holm-Bonferroni method would help you determine which diet pairs show significant differences.\n",
    "\n",
    "6. **Fisher's Least Significant Difference (LSD)**:\n",
    "   - When to use: Fisher's LSD is used for pairwise comparisons in cases where there are equal sample sizes and variances among groups.\n",
    "   - Example: You conducted an ANOVA to compare the heights of individuals from three different regions. Fisher's LSD would help identify which region pairs have significantly different average heights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f43d21-b1ad-4b5d-8479-7f1b0ce4ddeb",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9babf42-0a75-4b91-bdd2-7d0f1f7ed83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1185.216239215225\n",
      "p-value: 2.1253161002416956e-91\n",
      "There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for each diet\n",
    "diet_A = np.array([2.5, 3.2, 2.8, 3.5, 2.9, 3.1, 2.7, 2.6, 3.0, 3.3,\n",
    "                   3.2, 2.8, 3.4, 3.1, 2.9, 3.0, 2.7, 2.5, 3.1, 3.2,\n",
    "                   2.6, 2.9, 3.0, 3.3, 2.8, 3.1, 2.7, 2.5, 3.2, 3.4,\n",
    "                   2.9, 3.1, 2.8, 2.6, 3.0, 3.2, 2.7, 2.5, 3.1, 3.3,\n",
    "                   2.8, 3.0, 2.9, 3.2, 2.7, 2.6, 3.1, 3.4, 2.8, 3.0])\n",
    "\n",
    "diet_B = np.array([3.8, 4.2, 4.0, 3.6, 3.9, 3.7, 4.1, 4.3, 3.5, 3.9,\n",
    "                   4.0, 3.7, 3.4, 3.8, 3.6, 4.2, 3.9, 3.7, 3.8, 3.5,\n",
    "                   4.3, 3.6, 3.8, 4.0, 3.9, 3.7, 3.5, 3.4, 4.1, 4.2,\n",
    "                   3.7, 3.9, 3.8, 4.3, 3.6, 3.4, 3.9, 4.0, 3.8, 3.7,\n",
    "                   4.2, 3.5, 4.1, 3.6, 3.9, 3.7, 3.8, 3.4, 4.0, 3.6])\n",
    "\n",
    "diet_C = np.array([1.5, 1.2, 1.4, 1.7, 1.6, 1.3, 1.5, 1.8, 1.4, 1.6,\n",
    "                   1.7, 1.3, 1.2, 1.6, 1.5, 1.7, 1.3, 1.4, 1.6, 1.5,\n",
    "                   1.8, 1.7, 1.5, 1.4, 1.3, 1.6, 1.7, 1.2, 1.5, 1.6,\n",
    "                   1.8, 1.3, 1.7, 1.4, 1.5, 1.6, 1.2, 1.4, 1.8, 1.3,\n",
    "                   1.7, 1.5, 1.6, 1.2, 1.3, 1.4, 1.6, 1.7, 1.5, 1.8])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39364af5-05a6-4097-9d27-768d4b10320c",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d94591-5357-4c04-9f77-74ee19ff4d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Software:\n",
      "F-statistic: 2.0597679438747707\n",
      "p-value: 0.13738325450332742\n",
      "There is no significant main effect of software.\n",
      "\n",
      "Main Effect of Experience:\n",
      "F-statistic: 1.2692930383162777\n",
      "p-value: 0.2648811383167071\n",
      "There is no significant main effect of experience.\n",
      "\n",
      "Interaction Effect between Software and Experience:\n",
      "F-statistic: 0.5152455477603954\n",
      "p-value: 0.6002608594784352\n",
      "There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "software = ['A', 'B', 'C'] * 20\n",
    "experience = ['novice'] * 15 + ['experienced'] * 15 + ['novice'] * 15 + ['experienced'] * 15\n",
    "time = np.array([10.2, 9.8, 10.5, 9.5, 10.1, 10.3, 11.0, 9.7, 10.4, 10.6,\n",
    "                 11.2, 10.0, 10.8, 11.1, 11.5, 10.3, 9.9, 10.7, 9.8, 10.2,\n",
    "                 11.4, 10.3, 9.7, 10.1, 10.6, 11.2, 11.8, 11.0, 11.5, 11.7,\n",
    "                 9.5, 10.0, 9.9, 10.3, 10.6, 10.9, 11.1, 10.2, 10.7, 10.8,\n",
    "                 12.0, 11.5, 11.3, 10.4, 11.2, 10.8, 9.9, 10.5, 10.0, 10.3,\n",
    "                 10.8, 11.1, 10.7, 10.5, 10.3, 11.0, 11.5, 11.2, 11.8, 12.1])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Software': software, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('Time ~ Software + Experience + Software:Experience', data=df).fit()\n",
    "\n",
    "# Get the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "f_software = anova_table['F']['Software']\n",
    "p_software = anova_table['PR(>F)']['Software']\n",
    "\n",
    "f_experience = anova_table['F']['Experience']\n",
    "p_experience = anova_table['PR(>F)']['Experience']\n",
    "\n",
    "f_interaction = anova_table['F']['Software:Experience']\n",
    "p_interaction = anova_table['PR(>F)']['Software:Experience']\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"Main Effect of Software:\")\n",
    "print(\"F-statistic:\", f_software)\n",
    "print(\"p-value:\", p_software)\n",
    "if p_software < alpha:\n",
    "    print(\"There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of software.\")\n",
    "\n",
    "print(\"\\nMain Effect of Experience:\")\n",
    "print(\"F-statistic:\", f_experience)\n",
    "print(\"p-value:\", p_experience)\n",
    "if p_experience < alpha:\n",
    "    print(\"There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of experience.\")\n",
    "\n",
    "print(\"\\nInteraction Effect between Software and Experience:\")\n",
    "print(\"F-statistic:\", f_interaction)\n",
    "print(\"p-value:\", p_interaction)\n",
    "if p_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software and experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596b351-fc7d-47e5-b6ef-e980a184acf3",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ea92b7-996f-46c2-8c41-dfdef13e3c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "T-statistic: -7.193474763200661\n",
      "p-value: 8.824309089669441e-12\n",
      "There is a significant difference in test scores between the two groups.\n",
      "\n",
      "Tukey's HSD post-hoc test results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   4.3621   0.0 3.1673 5.5569   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "control_group = np.array([78, 82, 85, 73, 90, 88, 79, 84, 81, 76,\n",
    "                          77, 80, 83, 79, 87, 75, 82, 88, 74, 86,\n",
    "                          81, 78, 85, 80, 83, 89, 77, 84, 79, 82,\n",
    "                          86, 81, 84, 78, 82, 80, 75, 88, 83, 80,\n",
    "                          85, 87, 89, 78, 81, 83, 76, 79, 80, 88,\n",
    "                          85, 82, 86, 79, 84, 81, 76, 73, 78, 82,\n",
    "                          85, 73, 90, 88, 79, 84, 81, 76, 77, 80,\n",
    "                          83, 79, 87, 75, 82, 88, 74, 86, 81, 78,\n",
    "                          85, 80, 83, 89, 77, 84, 79, 82, 86, 81,\n",
    "                          84, 78, 82, 80, 75, 88, 83, 80, 85, 87,\n",
    "                          89, 78, 81, 83, 76, 79, 80, 88, 85, 82,\n",
    "                          86, 79, 84, 81, 76, 73])\n",
    "\n",
    "experimental_group = np.array([85, 88, 92, 76, 94, 90, 83, 86, 89, 80,\n",
    "                               82, 84, 87, 83, 91, 78, 86, 92, 75, 89,\n",
    "                               88, 85, 91, 86, 88, 93, 79, 87, 82, 85,\n",
    "                               91, 86, 88, 82, 84, 86, 80, 90, 87, 84,\n",
    "                               92, 94, 95, 85, 86, 87, 76, 79, 82, 91,\n",
    "                               89, 88, 93, 85, 90, 86, 80, 77, 85, 88,\n",
    "                               92, 76, 94, 90, 83, 86, 89, 80, 82, 84,\n",
    "                               87, 83, 91, 78, 86, 92, 75, 89, 88, 85,\n",
    "                               91, 86, 88, 93, 79, 87, 82, 85, 91, 86,\n",
    "                               88, 82, 84, 86, 80, 90, 87, 84, 92, 94,\n",
    "                               95, 85, 86, 87, 76, 79, 82, 91, 89, 88,\n",
    "                               93, 85, 90, 86, 80, 77])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print t-test results\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (Tukey's HSD)\n",
    "if p_value < alpha:\n",
    "    data = np.concatenate([control_group, experimental_group])\n",
    "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "    tukey_result = pairwise_tukeyhsd(data, group_labels)\n",
    "    print(\"\\nTukey's HSD post-hoc test results:\")\n",
    "    print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c12b0-826b-4bc2-a72c-5c1dff3a4036",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713d19ab-d838-44e5-a34c-82cd5670a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.672\n",
      "Model:                            OLS   Adj. R-squared:                  0.664\n",
      "Method:                 Least Squares   F-statistic:                     89.08\n",
      "Date:                Fri, 18 Aug 2023   Prob (F-statistic):           8.83e-22\n",
      "Time:                        08:11:42   Log-Likelihood:                -267.08\n",
      "No. Observations:                  90   AIC:                             540.2\n",
      "Df Residuals:                      87   BIC:                             547.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    104.5000      0.874    119.607      0.000     102.763     106.237\n",
      "Store[T.B]    -3.2667      1.236     -2.644      0.010      -5.723      -0.811\n",
      "Store[T.C]   -15.6333      1.236    -12.652      0.000     -18.089     -13.177\n",
      "==============================================================================\n",
      "Omnibus:                        1.620   Durbin-Watson:                   1.816\n",
      "Prob(Omnibus):                  0.445   Jarque-Bera (JB):                1.371\n",
      "Skew:                           0.135   Prob(JB):                        0.504\n",
      "Kurtosis:                       2.459   Cond. No.                         3.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Tukey's HSD post-hoc test results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "     A      B  -3.2667 0.0261  -6.2129  -0.3204   True\n",
      "     A      C -15.6333    0.0 -18.5796 -12.6871   True\n",
      "     B      C -12.3667    0.0 -15.3129  -9.4204   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "store_a_sales = np.array([100, 110, 105, 95, 102, 108, 98, 112, 100, 105,\n",
    "                          98, 102, 103, 106, 99, 108, 110, 115, 97, 105,\n",
    "                          112, 108, 100, 105, 107, 102, 101, 98, 115, 109])\n",
    "\n",
    "store_b_sales = np.array([95, 98, 105, 110, 108, 100, 92, 99, 105, 103,\n",
    "                          95, 100, 98, 105, 110, 108, 100, 92, 99, 105,\n",
    "                          103, 95, 100, 98, 105, 110, 108, 100, 92, 99])\n",
    "\n",
    "store_c_sales = np.array([90, 92, 85, 88, 92, 94, 88, 85, 90, 86,\n",
    "                          88, 92, 85, 88, 92, 94, 88, 85, 90, 86,\n",
    "                          88, 92, 85, 88, 92, 94, 88, 85, 90, 86])\n",
    "\n",
    "# Combine data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales]),\n",
    "    'Store': np.repeat(['A', 'B', 'C'], len(store_a_sales))\n",
    "})\n",
    "\n",
    "# Fit one-way ANOVA model\n",
    "model = ols('Sales ~ Store', data=data).fit()\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey_result = pairwise_tukeyhsd(endog=data['Sales'], groups=data['Store'], alpha=0.05)\n",
    "\n",
    "# Print ANOVA results\n",
    "print(\"One-way ANOVA results:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Print Tukey's HSD post-hoc test results\n",
    "print(\"\\nTukey's HSD post-hoc test results:\")\n",
    "print(tukey_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06410a-2f2e-469e-99a3-5e2fe3d8bbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
