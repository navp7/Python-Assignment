{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f266cf1e-25eb-48cd-918a-c94e4f8a84f2",
   "metadata": {},
   "source": [
    "# Ensemble Techniques And Its Types-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c8fb0-680a-43a3-9b9d-c216891e8712",
   "metadata": {},
   "source": [
    "### Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values:\n",
    "\n",
    "-- Design a pipeline that includes the following steps:\n",
    "\n",
    "-- Use an automated feature selection method to identify the important features in the dataset\n",
    "\n",
    "-- Create a numerical pipeline that includes the following steps:\n",
    "\n",
    "-- Impute the missing values in the numerical columns using the mean of the column values\n",
    "\n",
    "-- Scale the numerical columns using standardisation\n",
    "\n",
    "-- Create a categorical pipeline that includes the following steps:\n",
    "\n",
    "-- Impute the missing values in the categorical columns using the most frequent value of the column\n",
    "\n",
    "-- One-hot encode the categorical columns\n",
    "\n",
    "-- Combine the numerical and categorical pipelines using a ColumnTransformer:\n",
    "\n",
    "-- Use a Random Forest Classifier to build the final model\n",
    "\n",
    "-- Evaluate the accuracy of the model on the test dataset\n",
    "\n",
    "Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a2e7-f0ad-4cad-8d10-5e69ededdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data.drop('target_column', axis=1)\n",
    "y = data['target_column']\n",
    "\n",
    "# Step 1: Feature Selection\n",
    "# Use an automated feature selection method to identify important features\n",
    "# Example: Using a Random Forest for feature selection\n",
    "feature_selector = SelectFromModel(RandomForestClassifier())\n",
    "X_selected = feature_selector.fit_transform(X, y)\n",
    "\n",
    "# Step 2: Numerical Pipeline\n",
    "numerical_features = X_selected.select_dtypes(include=[np.number]).columns\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 3: Categorical Pipeline\n",
    "categorical_features = X_selected.select_dtypes(include=[np.object]).columns\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Step 4: Combine Numerical and Categorical Pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Final Model Pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Step 6: Train and Evaluate the Model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on the test dataset: {accuracy:.2f}')\n",
    "\n",
    "# Interpretation of Results:\n",
    "# We created a pipeline that selects important features, imputes missing values, scales numerical features,\n",
    "# and one-hot encodes categorical features before feeding them into a Random Forest Classifier.\n",
    "\n",
    "# Possible Improvements:\n",
    "# 1. Experiment with different feature selection methods to find the best set of features.\n",
    "# 2. Tune hyperparameters of the Random Forest Classifier for better performance.\n",
    "# 3. Consider other imputation methods or more advanced encoding techniques for categorical features.\n",
    "# 4. Use cross-validation to better estimate model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067959d7-48ee-4455-8f24-1d866e6643ec",
   "metadata": {},
   "source": [
    "### Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "50f28afe-8879-4b8a-b004-4e2e8309a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a247580a-1f4c-4b52-8302-bdd5ee6593a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "052d8377-19f2-48c0-b56d-3b28bb36c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf098a78-f268-4edf-b29f-f61dfd7240f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = iris_data['data'], columns = iris_data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d921fc6-f549-49b9-b5cb-acc56d01858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = iris_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e3662538-cb0e-48eb-9268-1ce43af27c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb0eebd6-53af-4a7a-a7a6-f23bc5dc6f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   species            150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "32ac7685-1841-49bb-9c00-e7ed003bc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4fc2d83d-e9bb-43c7-95c8-9e203060b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelining Numerical Features\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7fb50-8092-44ca-9a0a-25378ed4d38f",
   "metadata": {},
   "source": [
    "#### As we have only numerical features in our dataset we won't make pipeline for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9fa4f909-92af-4f8f-9b22-b5064c6d0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling Column Transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "16b64fcc-f167-4c53-8d32-23f68400d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "98f66638-bdff-498c-94a9-da629d22868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "23360716-106f-4ea3-bd8c-4f75a78b32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6f1886fb-679a-4a52-b11e-acd410d62ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Models Separately\n",
    "\n",
    "models={\n",
    "    'Random Forest':RandomForestClassifier(),\n",
    "    'Logistic Classifier':LogisticRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c434a069-c7e8-47bf-8dda-f2235e6f6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,y_train,X_test,y_test,models):\n",
    "    #This function will take training , testing and models data to predict the accuracy with respect to each model\n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        # Train model\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        # Predict Testing data\n",
    "        y_test_pred =model.predict(X_test)\n",
    "\n",
    "        # Get accuracy for test data prediction\n",
    "       \n",
    "        test_model_score = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "        report[list(models.keys())[i]] =  test_model_score\n",
    "                        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0b5221b-2c38-4b7f-87e5-b9a153054d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 1.0, 'Logistic Classifier': 1.0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train,X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50ece52e-55e4-4d02-b8b5-a41fa17c8237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Test Accuracy for Voting Classifier is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict Using Voting Classifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf1 = RandomForestClassifier()\n",
    "clf2 = LogisticRegression()\n",
    "\n",
    "# Checking Voting Classifier with soft voting\n",
    "v_clf1 = VotingClassifier(estimators=[('Random Forest', clf1), ('Logistic Classifier', clf2)], voting='soft')\n",
    "v_clf1.fit(X_train, y_train)\n",
    "y_pred_vc = v_clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_vc))\n",
    "print('Test Accuracy for Voting Classifier is',accuracy_score(y_test,y_pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4aeccda3-0d96-4f64-879a-298d3551848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Test Accuracy for Voting Classifier is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking Voting Classifier with hard voting\n",
    "\n",
    "v_clf2 = VotingClassifier(estimators=[('Random Forest', clf1), ('Logistic Classifier', clf2)], voting='hard')\n",
    "v_clf2.fit(X_train, y_train)\n",
    "y_pred_vc2 = v_clf2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_vc2))\n",
    "print('Test Accuracy for Voting Classifier is',accuracy_score(y_test,y_pred_vc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cb936-ce20-477f-baf7-0b81eb6e3bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
