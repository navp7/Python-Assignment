{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b62968-0c97-4cbb-bf57-4db17f840803",
   "metadata": {},
   "source": [
    "### Q1. What is Gradient Boosting Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7480f6-69a1-4174-945e-d62892f6df68",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression, often referred to as Gradient Boosting Machines (GBM), is a powerful machine learning technique used for regression tasks. It belongs to the family of ensemble methods, where multiple weak learners (typically decision trees) are combined to create a strong predictive model. Gradient Boosting Regression, specifically, is used for modeling and predicting continuous numeric values, making it a popular choice for regression problems.\n",
    "\n",
    "Here's how Gradient Boosting Regression works:\n",
    "\n",
    "1. **Base Model:** GBM starts with an initial model, typically a simple one, like a single decision tree with a fixed depth. This initial model serves as a weak learner.\n",
    "\n",
    "2. **Residual Calculation:** GBM identifies the errors or residuals between the actual target values and the predictions made by the initial model.\n",
    "\n",
    "3. **Building Ensembles:** A new weak learner (decision tree) is trained to predict the residuals from the previous step. The new model focuses on the errors made by the initial model and aims to correct them.\n",
    "\n",
    "4. **Update Predictions:** The predictions from the new weak learner are added to the predictions of the initial model to improve the overall model's predictions. The process of updating predictions by learning from residuals is repeated iteratively.\n",
    "\n",
    "5. **Gradient Descent:** GBM uses a gradient descent-like approach to minimize the loss function, optimizing the model to predict the target values more accurately with each iteration.\n",
    "\n",
    "6. **Stopping Criteria:** GBM continues this iterative process until a predefined stopping criteria are met, such as the number of weak learners or a specified level of performance improvement.\n",
    "\n",
    "The result is an ensemble of multiple decision trees, each of which is focused on correcting the errors made by the previous trees. The combined model provides a highly accurate and robust prediction for regression tasks.\n",
    "\n",
    "Some popular implementations of Gradient Boosting Regression include Gradient Boosting Machines (GBM), XGBoost, LightGBM, and CatBoost. These libraries provide efficient and optimized implementations of the algorithm, making it easy to use in various regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6e68c-c6f7-4881-b78d-d2f8a9346261",
   "metadata": {},
   "source": [
    "### Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a simple regression problem as an example and train the model on a small dataset. Evaluate the model's performance using metrics such as mean squared error and R-squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ccd3d93-bd3b-438b-80f2-21a63f0e94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error , r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1bcb32-4514-4021-bd34-a3779d43f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data for simple linear regression\n",
    "np.random.seed(1)\n",
    "\n",
    "X=np.random.randn(1000,1)  \n",
    "w=np.random.randn()\n",
    "b=np.random.randn()\n",
    "\n",
    "y=X*w+b +(np.random.randn(1000,1)*0.09)  #this last term of np.random.randn() is to add noise in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2811677-2de4-40b1-8381-357a2827ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 1), (300, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Test and Train Data:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 30)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee8fd7b-16c6-4463-a7f9-29be12c02219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_arr = scaler.fit_transform(X_train)\n",
    "X_test_arr= scaler.transform(X_test)\n",
    "\n",
    "y_arr = scaler.fit_transform(y_train)\n",
    "y_test_arr= scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17778c37-93b5-461e-9976-c337b9ce5968",
   "metadata": {},
   "source": [
    "## Manual Gradient Boosting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dece0889-fad5-4f0b-8368-b022ad1f59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Loss func\n",
    "def loss_calc(y_true,y_pred):\n",
    "    \n",
    "    loss = (1/len(y_true)) * 0.5*np.sum(np.square(y_true-y_pred))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Gradient Calc\n",
    "def gradient_calc(y_true,y_pred):\n",
    "    \n",
    "    grad = -(y_true-y_pred)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#The base estimator\n",
    "def tree_creator(r_state,X,y):\n",
    "    \n",
    "    d_tree = DecisionTreeRegressor(random_state=r_state,criterion='squared_error',\n",
    "                                    max_depth=2,min_samples_split=5,\n",
    "                                    min_samples_leaf=5,max_features=3)\n",
    "    d_tree.fit(X,y)\n",
    "    \n",
    "    return d_tree\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "#Predicting through gradient boosting regression\n",
    "def predict_grad_boost(models_tray,alpha,test_x=X_test_arr,train_y=y_arr):\n",
    "    \n",
    "    initial_pred = np.array([np.mean(train_y)] * len(test_x))\n",
    "        \n",
    "    final_pred = initial_pred.reshape(len(initial_pred),1)\n",
    "    #print(final_pred.shape)\n",
    "    \n",
    "    for i in range(len(models_tray)):\n",
    "        \n",
    "        model = models_tray[i]\n",
    "        temp_pred = (model.predict(test_x)).reshape(len(test_x),1)\n",
    "        #print(temp_pred.shape)\n",
    "        final_pred -= alpha * temp_pred\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cda334-af2f-4194-b29c-ea42264b9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost_train(train_x,train_y,alpha=0.01,r_state=100,n_iters=101):\n",
    "\n",
    "    model_tray = [] #Tray to collect the trained boosted stage estimators\n",
    "    loss_counter = [] #Tray for loss capture\n",
    "\n",
    "    \n",
    "    initial_pred = np.array([np.mean(train_y)] * len(train_y))\n",
    "\n",
    "    print('Initial val :',initial_pred.shape)\n",
    "    model_pred = initial_pred.reshape(len(initial_pred),1)\n",
    "\n",
    "    for epoch in range(n_iters): #Unit iteration\n",
    "\n",
    "        if epoch%100==0:\n",
    "            print('#---------- Epoch number :',epoch,' -----------#')\n",
    "        \n",
    "        #Calculating loss\n",
    "        loss = loss_calc(y_true=train_y,\n",
    "                         y_pred=model_pred)\n",
    "\n",
    "        loss_counter.append(loss)\n",
    "        \n",
    "        #Calculating the gradient (residuals)\n",
    "        grads = gradient_calc(y_true=train_y,\n",
    "                              y_pred=model_pred)\n",
    "        #print(grads.shape)\n",
    "        #Building the regression tree on the gradient (residuals)\n",
    "        tree_grad = tree_creator(r_state=r_state,\n",
    "                                 X=train_x,\n",
    "                                 y=grads)\n",
    "        #print(train_x.shape)\n",
    "        #print(tree_grad.predict(train_x).shape)\n",
    "        \n",
    "        #Predicting the residuals according to the tree fit above\n",
    "        pred_m = (tree_grad.predict(train_x)).reshape(len(train_x),1)\n",
    "        \n",
    "        #Updating model through learning rate\n",
    "        model_pred -= alpha * pred_m\n",
    "        \n",
    "        #Appending the model into tray\n",
    "        model_tray.append(tree_grad)\n",
    "        \n",
    "    return model_tray,loss_counter,initial_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcba87e6-a634-48c9-8136-1b20491cad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val : (700,)\n",
      "#---------- Epoch number : 0  -----------#\n",
      "#---------- Epoch number : 100  -----------#\n",
      "#---------- Epoch number : 200  -----------#\n",
      "#---------- Epoch number : 300  -----------#\n",
      "#---------- Epoch number : 400  -----------#\n",
      "#---------- Epoch number : 500  -----------#\n",
      "#---------- Epoch number : 600  -----------#\n",
      "#---------- Epoch number : 700  -----------#\n",
      "#---------- Epoch number : 800  -----------#\n",
      "#---------- Epoch number : 900  -----------#\n",
      "#---------- Epoch number : 1000  -----------#\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "#Defining some hyper-params\n",
    "n_estimators = 1001 #No of boosting steps\n",
    "alpha =0.01 #Learning rate\n",
    "\n",
    "#Training gradient boosting regression\n",
    "models_list,loss_counter,initial_pred = grad_boost_train(train_x=X_arr,\n",
    "                                                         train_y=y_arr,\n",
    "                                                         alpha=alpha,\n",
    "                                                         r_state=100,\n",
    "                                                         n_iters=n_estimators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd81daa-9698-4b5a-9579-7c6b1a716462",
   "metadata": {},
   "source": [
    "### Plotting the Loss curve (There should be a decrease in training loss over boosting rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b1757c-ce00-4519-9cfb-20fa96618a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Number of boosting rounds'),\n",
       " Text(0, 0.5, 'Loss'),\n",
       " Text(0.5, 1.0, 'Loss vs Boosting rounds plot')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "ax = sns.lineplot(x=range(n_estimators),y=loss_counter)\n",
    "ax.set(xlabel='Number of boosting rounds',ylabel='Loss',title='Loss vs Boosting rounds plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f050b883-8182-4f73-94d6-ba270945536b",
   "metadata": {},
   "source": [
    "### Predicting on the test dataset using the manual training above (Only the trained residual models are passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946bc052-2b23-405c-8da4-f086788be36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_gbm_pred = predict_grad_boost(models_tray=models_list, #Passing the fitted estimators into the predict function\n",
    "                                     alpha=alpha, #The alpha val used during training\n",
    "                                     test_x=X_test_arr) #Test dataset\n",
    "manual_gbm_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3d094-204b-42e5-aa22-33ba616647fe",
   "metadata": {},
   "source": [
    "### Evaluating the predictions from the manual gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14679779-7d04-4810-b4a7-63a2c3c42638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of test set : 0.295785342825056\n",
      "RMSE of test set : 0.5438615107038335\n",
      "R2 score of test set : 0.6919340773160432\n"
     ]
    }
   ],
   "source": [
    "print('MSE of test set :',mean_squared_error(y_test_arr,manual_gbm_pred))\n",
    "print('RMSE of test set :',np.sqrt(mean_squared_error(y_test_arr,manual_gbm_pred)))\n",
    "print('R2 score of test set :',r2_score(y_test_arr,manual_gbm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4469ad-8543-4897-b130-4a889ce4f58c",
   "metadata": {},
   "source": [
    "### Benchmarking against sklearn implementation of gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b75d09c5-8b93-49b0-a7c0-83d8f112e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of test set : 0.33899806530461823\n",
      "RMSE of test set : 0.5822354036853292\n",
      "R2 score of test set : 0.6469272250656739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "skl_gbm = GradientBoostingRegressor(random_state=100,n_estimators=1001,criterion='squared_error',\n",
    "                                    max_depth=2,min_samples_split=5,\n",
    "                                    min_samples_leaf=5,max_features=3)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "skl_gbm.fit(X_arr,y_arr)\n",
    "skl_pred = skl_gbm.predict(X_test_arr)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "print('MSE of test set :',mean_squared_error(y_test_arr,skl_pred))\n",
    "print('RMSE of test set :',np.sqrt(mean_squared_error(y_test_arr,skl_pred)))\n",
    "print('R2 score of test set :',r2_score(y_test_arr,skl_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd4261-e257-4f68-8681-db8c948ab158",
   "metadata": {},
   "source": [
    "Final Comments :\n",
    "    \n",
    "The manual implementation of the gradient boosting algorithm is providing similar results to its sklearn counterpart \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7619425-5429-434d-b3bc-e3a4e1213fb7",
   "metadata": {},
   "source": [
    "### Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to optimise the performance of the model. Use grid search or random search to find the best hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3cb084-eda3-485e-86a2-c30d089bd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = GradientBoostingRegressor()\n",
    "params  = {\n",
    "    'loss':['squared_error', 'absolute_error'],\n",
    "    'learning_rate':[0.1,0.01,1],\n",
    "    'n_estimators':[10,20,40,50,70,80,100,120,150,200],\n",
    "    'criterion':['friedman_mse', 'squared_error'],\n",
    "    'min_samples_split':[2,4,6,8,10],\n",
    "    'min_samples_leaf': [1, 3, 4],\n",
    "    'max_depth':[1,2,4,6,8],\n",
    "    'max_features':['sqrt', 'log2']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69531648-9a2c-4e32-8994-dbe8cfeabf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = RandomizedSearchCV(estimator = model,param_distributions = params,\n",
    "               n_iter = 100, cv = 5 ,verbose = 3, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f49cafd-358a-4f31-a76f-aaae4f8678b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=80;, score=-0.492 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=80;, score=-0.325 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=80;, score=-0.391 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=80;, score=-0.532 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=80;, score=-0.487 total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.334 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.368 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.352 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.362 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.392 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=-0.430 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=-0.304 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=-0.350 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=-0.480 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=-0.434 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=-0.410 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=-0.314 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=-0.355 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=-0.466 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=100;, score=-0.411 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=-0.625 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=-0.412 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=-0.485 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=-0.695 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=-0.617 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.271 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.262 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.273 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.309 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.289 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.487 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.465 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.441 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.504 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.847 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.596 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.651 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.939 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.855 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=20;, score=-0.406 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=20;, score=-0.290 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=20;, score=-0.327 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=20;, score=-0.454 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=20;, score=-0.422 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.280 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.276 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.291 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.302 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.299 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.373 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.412 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.473 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.394 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.453 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=10;, score=-0.318 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=10;, score=-0.278 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=10;, score=-0.314 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=10;, score=-0.316 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=10;, score=-0.338 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.352 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.385 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.401 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.386 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.401 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.448 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.530 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.556 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.471 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.568 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=-0.294 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=-0.288 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=-0.306 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=-0.305 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=-0.302 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.312 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.329 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.372 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.343 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.374 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.284 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.276 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.308 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.292 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.286 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.571 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.460 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.661 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.584 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.275 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.272 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.310 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.301 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.311 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.280 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.295 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.292 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.306 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=40;, score=-0.306 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.832 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.595 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.616 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.937 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.867 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=120;, score=-0.359 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=120;, score=-0.281 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=120;, score=-0.320 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=120;, score=-0.416 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=120;, score=-0.361 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.347 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.376 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.368 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.375 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.397 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=40;, score=-0.645 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=40;, score=-0.469 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=40;, score=-0.510 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=40;, score=-0.733 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=40;, score=-0.661 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.668 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.469 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.496 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.760 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.712 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.334 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.287 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.310 total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.371 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20;, score=-0.342 total time=   0.3s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150;, score=-0.275 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150;, score=-0.273 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150;, score=-0.288 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150;, score=-0.298 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150;, score=-0.306 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=70;, score=-0.300 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=70;, score=-0.284 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=70;, score=-0.313 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=70;, score=-0.333 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=70;, score=-0.347 total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.406 total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.459 total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.425 total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.421 total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.460 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.489 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.325 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.387 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.533 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.488 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=70;, score=-0.318 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=70;, score=-0.336 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=70;, score=-0.383 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=70;, score=-0.342 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=70;, score=-0.369 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=120;, score=-0.390 total time=   0.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=120;, score=-0.280 total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=120;, score=-0.328 total time=   0.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=120;, score=-0.425 total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=120;, score=-0.388 total time=   0.6s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=20;, score=-0.816 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=20;, score=-0.582 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=20;, score=-0.637 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=20;, score=-0.921 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=20;, score=-0.831 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=20;, score=-0.307 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=20;, score=-0.276 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=20;, score=-0.311 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=20;, score=-0.356 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=20;, score=-0.344 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=-0.412 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=-0.455 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=-0.523 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=-0.425 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=-0.507 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=-0.506 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=-0.574 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=-0.649 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=-0.520 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=100;, score=-0.632 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=-0.294 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=-0.296 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=-0.304 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=-0.319 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=100;, score=-0.322 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=-0.301 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=-0.249 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=-0.282 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=-0.319 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=-0.308 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.918 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.661 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.696 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-1.029 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.949 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.389 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.281 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.324 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.426 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=120;, score=-0.391 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=80;, score=-0.488 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=80;, score=-0.340 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=80;, score=-0.389 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=80;, score=-0.551 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=80;, score=-0.492 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=120;, score=-0.400 total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=120;, score=-0.425 total time=   0.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=120;, score=-0.493 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=120;, score=-0.444 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=120;, score=-0.473 total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.568 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.412 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.458 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.661 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.576 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.719 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.517 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.558 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.831 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=40;, score=-0.786 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.538 total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.349 total time=   0.7s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.431 total time=   0.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.585 total time=   0.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.528 total time=   0.7s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.311 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.265 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.296 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.353 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=20;, score=-0.331 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.288 total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.269 total time=   0.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.303 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.301 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.309 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=40;, score=-0.296 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=40;, score=-0.278 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=40;, score=-0.316 total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=40;, score=-0.331 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=40;, score=-0.340 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.340 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.355 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.359 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.364 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=40;, score=-0.373 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=120;, score=-0.453 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=120;, score=-0.494 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=120;, score=-0.596 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=120;, score=-0.472 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=120;, score=-0.549 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.341 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.353 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.373 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.397 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.400 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=40;, score=-0.314 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=40;, score=-0.318 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=40;, score=-0.334 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=40;, score=-0.339 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=40;, score=-0.343 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.386 total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.270 total time=   0.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.318 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.418 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.388 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.432 total time=   1.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.494 total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.428 total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.428 total time=   1.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=-0.489 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=70;, score=-0.387 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=70;, score=-0.444 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=70;, score=-0.467 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=70;, score=-0.403 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=70;, score=-0.512 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20;, score=-0.325 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20;, score=-0.300 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20;, score=-0.318 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20;, score=-0.359 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20;, score=-0.338 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.282 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.284 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.300 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.308 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=-0.312 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.388 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.289 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.336 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.445 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.398 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.487 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.507 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.587 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.454 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=-0.559 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.347 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.376 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.368 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.375 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=80;, score=-0.397 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.288 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.269 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.303 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.301 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.309 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=70;, score=-0.406 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=70;, score=-0.459 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=70;, score=-0.425 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=70;, score=-0.421 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=70;, score=-0.460 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70;, score=-0.475 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70;, score=-0.343 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70;, score=-0.391 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70;, score=-0.546 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70;, score=-0.483 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=-0.333 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=-0.338 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=-0.341 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=-0.329 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=-0.341 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.271 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.254 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.279 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.285 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=70;, score=-0.289 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.520 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.376 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.387 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.605 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=150;, score=-0.570 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.314 total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.318 total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.323 total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.365 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=40;, score=-0.339 total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.571 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.412 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.460 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.661 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=50;, score=-0.584 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=-0.318 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=-0.332 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=-0.333 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=-0.347 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=-0.361 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.323 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.349 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.343 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.353 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80;, score=-0.369 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.517 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.577 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.654 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.522 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.637 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=-0.291 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=-0.278 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=-0.310 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=-0.293 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100;, score=-0.290 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=80;, score=-0.296 total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=80;, score=-0.314 total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=80;, score=-0.322 total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=80;, score=-0.353 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=80;, score=-0.355 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.320 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.349 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.400 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.358 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=-0.378 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.273 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.254 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.274 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.308 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.289 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=150;, score=-0.271 total time=   0.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=150;, score=-0.262 total time=   0.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=150;, score=-0.273 total time=   0.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=150;, score=-0.309 total time=   0.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=150;, score=-0.289 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=120;, score=-0.391 total time=   1.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=120;, score=-0.284 total time=   1.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=120;, score=-0.332 total time=   1.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=120;, score=-0.432 total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=120;, score=-0.385 total time=   1.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.274 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.255 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.273 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.309 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.289 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.488 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.340 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.389 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.551 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=80;, score=-0.492 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=70;, score=-0.287 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=70;, score=-0.256 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=70;, score=-0.282 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=70;, score=-0.301 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=70;, score=-0.290 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.301 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.249 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.282 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.319 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.308 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.432 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.486 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.415 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.428 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=70;, score=-0.489 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.478 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.462 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.492 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.437 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.538 total time=   0.3s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.351 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.366 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.435 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.413 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=20;, score=-0.441 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=10;, score=-0.951 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=10;, score=-0.689 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=10;, score=-0.736 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=10;, score=-1.060 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=10;, score=-0.974 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.280 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.276 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.291 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.302 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=squared_error, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40;, score=-0.299 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.288 total time=   0.2s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.269 total time=   0.2s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.303 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.301 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120;, score=-0.309 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=70;, score=-0.290 total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=70;, score=-0.270 total time=   0.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=70;, score=-0.301 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=70;, score=-0.320 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=70;, score=-0.316 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=-0.662 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=-0.469 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=-0.510 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=-0.770 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=absolute_error, max_depth=2, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=50;, score=-0.728 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.525 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.366 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.414 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.597 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=70;, score=-0.530 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.389 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.281 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.324 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.426 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.01, loss=squared_error, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120;, score=-0.391 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.517 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.577 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.653 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.520 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=-0.636 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=10;, score=-0.333 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=10;, score=-0.296 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=10;, score=-0.341 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=10;, score=-0.311 total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=squared_error, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=10;, score=-0.293 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=-0.296 total time=   0.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=-0.281 total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=-0.325 total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=-0.335 total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=absolute_error, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=-0.367 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.290 total time=   0.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.285 total time=   0.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.306 total time=   0.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.297 total time=   0.1s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=squared_error, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=150;, score=-0.296 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.353 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.289 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.349 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.313 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=50;, score=-0.340 total time=   0.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.311 total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.311 total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.324 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.332 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=-0.336 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=20;, score=-0.328 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=20;, score=-0.254 total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=20;, score=-0.288 total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=20;, score=-0.350 total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=absolute_error, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=20;, score=-0.334 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=50;, score=-0.336 total time=   0.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=50;, score=-0.357 total time=   0.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=50;, score=-0.365 total time=   0.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=50;, score=-0.362 total time=   0.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=squared_error, max_depth=8, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=50;, score=-0.373 total time=   0.1s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=-0.505 total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=-0.534 total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=-0.563 total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=-0.503 total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=1, loss=absolute_error, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=-0.602 total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 1],\n",
       "                                        &#x27;loss&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                 &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 20, 40, 50, 70, 80,\n",
       "                                                         100, 120, 150, 200]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 1],\n",
       "                                        &#x27;loss&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                 &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 4, 6, 8],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 20, 40, 50, 70, 80,\n",
       "                                                         100, 120, 150, 200]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_iter=100,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error'],\n",
       "                                        'learning_rate': [0.1, 0.01, 1],\n",
       "                                        'loss': ['squared_error',\n",
       "                                                 'absolute_error'],\n",
       "                                        'max_depth': [1, 2, 4, 6, 8],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 3, 4],\n",
       "                                        'min_samples_split': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [10, 20, 40, 50, 70, 80,\n",
       "                                                         100, 120, 150, 200]},\n",
       "                   scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_arr,y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7ca0c26-09f8-4ac4-b8d2-70e98a110f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 70,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 1,\n",
       " 'loss': 'squared_error',\n",
       " 'learning_rate': 0.1,\n",
       " 'criterion': 'squared_error'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25307b95-372a-41b7-bb14-5c99803cd386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=1,\n",
       "                          max_features=&#x27;sqrt&#x27;, n_estimators=70)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=1,\n",
       "                          max_features=&#x27;sqrt&#x27;, n_estimators=70)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(criterion='squared_error', max_depth=1,\n",
       "                          max_features='sqrt', n_estimators=70)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a02f08d-ba1d-46b9-8c22-6205a781ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a16e89b-4463-4b0f-a474-e43cb32ba96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=1,\n",
       "                          max_features=&#x27;sqrt&#x27;, n_estimators=70)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(criterion=&#x27;squared_error&#x27;, max_depth=1,\n",
       "                          max_features=&#x27;sqrt&#x27;, n_estimators=70)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(criterion='squared_error', max_depth=1,\n",
       "                          max_features='sqrt', n_estimators=70)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB.fit(X_arr,y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e86cd0dd-a7cf-4cd1-aba9-3408d78af3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best=GB.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc629df4-c36e-46bf-a104-45432b35efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of test set : 0.28526996724985204\n",
      "RMSE of test set : 0.5341067002480422\n",
      "R2 score of test set : 0.7028860360845326\n"
     ]
    }
   ],
   "source": [
    "print('MSE of test set :',mean_squared_error(y_test_arr,y_pred_best))\n",
    "print('RMSE of test set :',np.sqrt(mean_squared_error(y_test_arr,y_pred_best)))\n",
    "print('R2 score of test set :',r2_score(y_test_arr,y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c4fd8-9c1b-49bb-99c0-5be9045063c0",
   "metadata": {},
   "source": [
    "### Hence, after hyperparameter tuning we got an R2 score of 0.7028860360845326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2b8be-d097-437c-a3de-45da605abec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b0afd-7250-4c81-8d3b-5c06e7aef2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be5995a1-a0a6-44a5-a2ca-0568445fbe8d",
   "metadata": {},
   "source": [
    "### Q4. What is a weak learner in Gradient Boosting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa02a9e-1061-439f-bd3f-c54be2d12c32",
   "metadata": {},
   "source": [
    "- In the context of Gradient Boosting, a weak learner refers to a machine learning model or algorithm that is only slightly better than random guessing for the given problem. Weak learners are typically simple models with limited complexity, such as shallow decision trees or linear models.\n",
    "\n",
    "- Weak learners are deliberately chosen to be weak because the strength of the Gradient Boosting algorithm comes from the ensemble of multiple such weak learners. These weak learners focus on correcting the errors made by previous models in the ensemble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df3160-d433-4005-a36d-84d98e0632ae",
   "metadata": {},
   "source": [
    "### Q5. What is the intuition behind the Gradient Boosting algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c474f0-5347-412b-8bd4-10b3f07eacc8",
   "metadata": {},
   "source": [
    "\n",
    "   - The intuition behind the Gradient Boosting algorithm can be summarized as follows:\n",
    "\n",
    "   1. **Iterative Error Correction:** Gradient Boosting is an ensemble technique that aims to create a strong predictive model by combining multiple weak learners. It works iteratively, where each weak learner focuses on correcting the errors made by the previous ones.\n",
    "\n",
    "   2. **Sequential Learning:** Weak learners are added sequentially to the ensemble. The first learner starts with an initial approximation, and each subsequent learner tries to reduce the errors (residuals) of the ensemble up to that point.\n",
    "\n",
    "   3. **Gradient Descent:** Gradient Boosting uses a gradient descent-like approach to minimize the loss function. The new learners are fit to the gradients of the loss function with respect to the ensemble's predictions. This guides the algorithm to move in the direction that reduces the errors.\n",
    "\n",
    "   4. **Model Combination:** The final prediction is the result of combining the predictions from all weak learners. Each weak learner contributes a part of the prediction, and they are weighted based on their performance.\n",
    "\n",
    "   5. **Strong Predictive Power:** The ensemble of weak learners, when combined, provides a strong predictive model capable of capturing complex relationships in the data and minimizing the prediction error.\n",
    "\n",
    "   6. **Robustness:** Gradient Boosting is robust against overfitting because of its sequential and iterative nature. It can learn from errors made by earlier learners and, in some cases, outperform other machine learning algorithms.\n",
    "\n",
    "   Overall, Gradient Boosting's success lies in its ability to combine simple models in a way that creates a highly accurate and robust predictive model for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44910d-449e-4942-8a4b-3b93c01284cf",
   "metadata": {},
   "source": [
    "### Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c6474-6052-41d5-a922-0cb28aff76b0",
   "metadata": {},
   "source": [
    "\n",
    "   - Gradient Boosting builds an ensemble of weak learners in an iterative and sequential manner. Here's how the algorithm constructs the ensemble:\n",
    "\n",
    "   1. **Initialization:** Gradient Boosting starts with an initial weak learner, which can be a simple model like a shallow decision tree. The initial model serves as the first base learner in the ensemble.\n",
    "\n",
    "   2. **Error Calculation:** The algorithm calculates the errors or residuals between the actual target values and the predictions made by the initial model. These errors represent the discrepancies between the model's predictions and the true values.\n",
    "\n",
    "   3. **Training New Learners:** A new weak learner (e.g., another decision tree) is trained to predict these errors, focusing on the areas where the initial model performed poorly. The new learner is designed to correct the errors made by the previous model.\n",
    "\n",
    "   4. **Updating Predictions:** The predictions from the new weak learner are added to the predictions of the initial model. This updated ensemble of models aims to provide better predictions, with the new learner addressing the errors made by the previous one.\n",
    "\n",
    "   5. **Gradient Descent:** Gradient Boosting uses a gradient descent-like approach to optimize the ensemble's predictions. It adjusts the new learner's parameters to minimize the loss function, guiding the model in the direction that reduces the errors.\n",
    "\n",
    "   6. **Iterative Process:** Steps 3 to 5 are repeated for a predefined number of iterations or until a specified stopping criteria are met. Each iteration introduces a new learner that refines the predictions.\n",
    "\n",
    "   7. **Combining Predictions:** The final prediction is the result of combining the predictions from all weak learners. Each learner contributes to the overall prediction, and their contributions are weighted based on their performance in reducing errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72663007-e383-4138-ae87-fd657cc13a4c",
   "metadata": {},
   "source": [
    "### Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785b939-9afc-4a3b-8f6c-0c0cd0611f52",
   "metadata": {},
   "source": [
    "\n",
    "   - The mathematical intuition behind Gradient Boosting can be summarized in the following steps:\n",
    "\n",
    "   1. **Initialization:** Start with an initial approximation, which can be a simple model like a decision tree with limited depth.\n",
    "\n",
    "   2. **Error Calculation:** Calculate the errors or residuals by finding the differences between the actual target values and the predictions made by the initial model.\n",
    "\n",
    "   3. **Gradient Calculation:** Compute the gradient (partial derivatives) of the loss function with respect to the model's predictions. This gradient represents how the loss would change with small adjustments to the model's predictions.\n",
    "\n",
    "   4. **Training New Learner:** Train a new weak learner (e.g., another decision tree) to predict the negative gradient, aiming to reduce the errors. This learner is fitted to the residuals of the loss function.\n",
    "\n",
    "   5. **Update Predictions:** Add the predictions from the new learner to the initial model's predictions. This combined model is closer to the true target values than the initial model.\n",
    "\n",
    "   6. **Gradient Descent:** The new learner is fitted in the direction of the negative gradient, which minimizes the loss function. It adjusts its parameters to reduce the errors further.\n",
    "\n",
    "   7. **Iterative Process:** Steps 3 to 6 are repeated for a predefined number of iterations. Each new learner focuses on the remaining errors not yet captured by the ensemble.\n",
    "\n",
    "   8. **Final Prediction:** The final prediction is the result of combining the predictions from all the learners in the ensemble. The weights of these predictions are determined based on the performance of each learner.\n",
    "\n",
    "By following these steps, the Gradient Boosting algorithm constructs an ensemble of weak learners that, when combined, provides a powerful and accurate predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b57c4-7792-44ac-bc8c-921a50e4d1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb719d-ded6-4d1e-a430-048d33464ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a847d3b-95d0-4150-b72d-62e66e6e186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162123ed-b95a-4544-b837-4c83e5210023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bd006-2fa1-4633-ac46-3b6b64f77dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abcade-82c2-4bf0-8a40-55aff48a432e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2898c-9c50-4153-ae0f-a1779ff4238d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97052348-9005-45a8-a8a9-fbf33df3cfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333daa94-2418-4f80-a764-6a5cf6fba84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2fd02-9441-4889-ae95-877b90314cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1be89-dfae-4979-ab4d-27a8f9bb7f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa0302-ffc0-497b-a2ea-07a198768c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
